{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from evaluation import PerplexityCalculator\n",
    "path_model = \"/home/task/.cache/kagglehub/models/google/gemma-2/transformers/gemma-2-9b/2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"sleigh of holiday cheer unwrap gifts relax eat yuletide cheer sing carol the magi visit workshop grinch is naughty and nice decorations ornament chimney stocking nutcracker polar beard holly jingle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dcbcfcfb4ea4683b523687b64f3ccb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scorer = PerplexityCalculator(model_path=str(path_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198.9331323667161"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scorer.get_perplexity(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = text.split()\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import random\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_neighbor_1(words_input: list[str]) -> list[str]:\n",
    "    \"\"\"ランダムに単語を選んでランダムな箇所に挿入\"\"\"\n",
    "    words = words_input.copy()\n",
    "    idx = random.randint(0, len(words) - 1)\n",
    "    word = words.pop(idx)\n",
    "    idx_insert = random.randint(0, len(words))\n",
    "    words.insert(idx_insert, word)\n",
    "    return words\n",
    "\n",
    "\n",
    "def make_neighbor_2(words_input: list[str]) -> list[str]:\n",
    "    \"\"\"ランダムに単語の列を選んでランダムな箇所に挿入\"\"\"\n",
    "    words = words_input.copy()\n",
    "    idx1 = random.randint(0, len(words))\n",
    "    idx2 = random.randint(0, len(words))\n",
    "    if idx1 == idx2:\n",
    "        return None\n",
    "    if idx1 > idx2:\n",
    "        idx1, idx2 = idx2, idx1\n",
    "    words_mid = words[idx1:idx2]\n",
    "    words_rest = words[:idx1] + words[idx2:]\n",
    "    idx_insert = random.randint(0, len(words_rest))\n",
    "    words_new = words_rest[:idx_insert] + words_mid + words_rest[idx_insert:]\n",
    "    return words_new\n",
    "\n",
    "\n",
    "def make_neighbor_3(words_input: list[str]) -> list[str]:\n",
    "    \"\"\"ランダムに単語の列を選んで先頭か末尾に移動\"\"\"\n",
    "    words = words_input.copy()\n",
    "    idx1 = random.randint(1, len(words))\n",
    "    idx2 = random.randint(1, len(words))\n",
    "    if idx1 == idx2:\n",
    "        return None\n",
    "    if idx1 > idx2:\n",
    "        idx1, idx2 = idx2, idx1\n",
    "    words1 = words[:idx1]\n",
    "    words2 = words[idx1:idx2]\n",
    "    words3 = words[idx2:]\n",
    "    coin = random.randint(1, 2)\n",
    "    if coin == 1:\n",
    "        words_new = words1 + words3 + words2\n",
    "    else:\n",
    "        words_new = words2 + words1 + words3\n",
    "    return words_new\n",
    "\n",
    "\n",
    "def make_neighbor_4(words_input: list[str]) -> list[str]:\n",
    "    \"\"\"Rotate\"\"\"\n",
    "    words = words_input.copy()\n",
    "    idx = random.randint(1, len(words) - 1)\n",
    "    words_new = words[idx:] + words[:idx]\n",
    "    return words_new\n",
    "\n",
    "\n",
    "def make_neighbor_5(words_input: list[str]) -> list[str]:\n",
    "    \"\"\"隣接した単語を入れ替える\"\"\"\n",
    "    words = words_input.copy()\n",
    "    idx = random.randint(0, len(words) - 2)\n",
    "    words[idx], words[idx + 1] = words[idx + 1], words[idx]\n",
    "    return words\n",
    "\n",
    "\n",
    "def make_neighbor_6(words_input: list[str]) -> list[str]:\n",
    "    \"\"\"区間を反転する\"\"\"\n",
    "    words = words_input.copy()\n",
    "    idx1 = random.randint(0, len(words))\n",
    "    idx2 = (idx1 + random.randint(2, len(words) - 2)) % len(words)\n",
    "    if idx1 > idx2:\n",
    "        idx1, idx2 = idx2, idx1\n",
    "    words[idx1:idx2] = words[idx1:idx2][::-1]\n",
    "    return words\n",
    "\n",
    "\n",
    "def make_neighbor_7(words_input: list[str]) -> list[str]:\n",
    "    \"\"\"ランダムな 2 単語を入れ替える\"\"\"\n",
    "    words = words_input.copy()\n",
    "    idx1 = random.randint(0, len(words) - 1)\n",
    "    idx2 = (idx1 + random.randint(1, len(words) - 1)) % len(words)\n",
    "    words[idx1], words[idx2] = words[idx2], words[idx1]\n",
    "    return words\n",
    "\n",
    "neighbor_prob = {\n",
    "            1: 10.0,\n",
    "            2: 5.0,\n",
    "            3: 5.0,\n",
    "            4: 1.0,\n",
    "            5: 5.0,\n",
    "            6: 1.0,\n",
    "            7: 1.0,\n",
    "        }\n",
    "\n",
    "prob_total = sum(neighbor_prob.values())\n",
    "for key in neighbor_prob:\n",
    "    neighbor_prob[key] = neighbor_prob[key] / prob_total\n",
    "\n",
    "def make_neighbor(\n",
    "    words_input: list[str], neighbor_prob: dict[int, float] = neighbor_prob\n",
    ") -> tuple[list[str], int]:\n",
    "    \"\"\"ランダムに操作を行う\"\"\"\n",
    "    words_return = None\n",
    "    while words_return is None:\n",
    "        coin = int(\n",
    "            np.random.choice(list(neighbor_prob.keys()), p=list(neighbor_prob.values()))\n",
    "        )\n",
    "        if coin == 1:\n",
    "            words_return = make_neighbor_1(words_input)\n",
    "        elif coin == 2:\n",
    "            words_return = make_neighbor_2(words_input)\n",
    "        elif coin == 3:\n",
    "            words_return = make_neighbor_3(words_input)\n",
    "        elif coin == 4:\n",
    "            words_return = make_neighbor_4(words_input)\n",
    "        elif coin == 5:\n",
    "            words_return = make_neighbor_5(words_input)\n",
    "        elif coin == 6:\n",
    "            words_return = make_neighbor_6(words_input)\n",
    "        elif coin == 7:\n",
    "            words_return = make_neighbor_7(words_input)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid neighbor function coin\")\n",
    "        if words_return == words_input:\n",
    "            words_return = None\n",
    "    assert sorted(words_input) == sorted(words_return)\n",
    "    return words_return, coin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create some initial solutions\n",
    "n_words = len(words)\n",
    "n_pop = 100\n",
    "pop = []\n",
    "for _ in range(n_pop):\n",
    "    random.shuffle(words)\n",
    "    pop.append(copy.deepcopy(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:49<00:00,  1.10s/it, score=399]   \n",
      "  5%|▌         | 5/100 [00:06<02:01,  1.27s/it, score=1.14e+3]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[196], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m     words_tmp, _ \u001b[38;5;241m=\u001b[39m make_neighbor(words_best)\n\u001b[1;32m     13\u001b[0m     candidates\u001b[38;5;241m.\u001b[39mappend(words_tmp)\n\u001b[0;32m---> 14\u001b[0m     scores\u001b[38;5;241m.\u001b[39mappend(\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_perplexity\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwords_tmp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# 元の解も含めて最良のものを選択\u001b[39;00m\n\u001b[1;32m     17\u001b[0m candidates\u001b[38;5;241m.\u001b[39mappend(words_best)\n",
      "File \u001b[0;32m~/santa2024/code_kibuna/notebook/../evaluation.py:310\u001b[0m, in \u001b[0;36mPerplexityCalculator.get_perplexity\u001b[0;34m(self, input_texts, batch_size)\u001b[0m\n\u001b[1;32m    307\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mto(DEVICE) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m model_inputs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    309\u001b[0m \u001b[38;5;66;03m# Get model output\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    311\u001b[0m logits \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogits\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    313\u001b[0m label \u001b[38;5;241m=\u001b[39m model_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/santa2024/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/santa2024/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/santa2024/.venv/lib/python3.12/site-packages/transformers/models/gemma2/modeling_gemma2.py:1049\u001b[0m, in \u001b[0;36mGemma2ForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, num_logits_to_keep, **loss_kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1049\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1051\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1053\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1056\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1059\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1060\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1062\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "File \u001b[0;32m~/santa2024/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/santa2024/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/santa2024/.venv/lib/python3.12/site-packages/transformers/models/gemma2/modeling_gemma2.py:837\u001b[0m, in \u001b[0;36mGemma2Model.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    826\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    827\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    828\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    834\u001b[0m         cache_position,\n\u001b[1;32m    835\u001b[0m     )\n\u001b[1;32m    836\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 837\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    847\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    849\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/santa2024/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/santa2024/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/santa2024/.venv/lib/python3.12/site-packages/transformers/models/gemma2/modeling_gemma2.py:553\u001b[0m, in \u001b[0;36mGemma2DecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position)\u001b[0m\n\u001b[1;32m    550\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    552\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 553\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    562\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_attention_layernorm(hidden_states)\n\u001b[1;32m    563\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n",
      "File \u001b[0;32m~/santa2024/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/santa2024/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/santa2024/.venv/lib/python3.12/site-packages/transformers/models/gemma2/modeling_gemma2.py:229\u001b[0m, in \u001b[0;36mGemma2Attention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position)\u001b[0m\n\u001b[1;32m    226\u001b[0m value_states \u001b[38;5;241m=\u001b[39m value_states\u001b[38;5;241m.\u001b[39mview(bsz, q_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_key_value_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    228\u001b[0m cos, sin \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrotary_emb(value_states, position_ids)\n\u001b[0;32m--> 229\u001b[0m query_states, key_states \u001b[38;5;241m=\u001b[39m \u001b[43mapply_rotary_pos_emb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;66;03m# sin and cos are specific to RoPE models; cache_position needed for the static cache\u001b[39;00m\n\u001b[1;32m    233\u001b[0m     cache_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    234\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msin\u001b[39m\u001b[38;5;124m\"\u001b[39m: sin,\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcos\u001b[39m\u001b[38;5;124m\"\u001b[39m: cos,\n\u001b[1;32m    236\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msliding_window\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msliding_window,\n\u001b[1;32m    237\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache_position\u001b[39m\u001b[38;5;124m\"\u001b[39m: cache_position,\n\u001b[1;32m    238\u001b[0m     }\n",
      "File \u001b[0;32m~/santa2024/.venv/lib/python3.12/site-packages/transformers/models/gemma2/modeling_gemma2.py:150\u001b[0m, in \u001b[0;36mapply_rotary_pos_emb\u001b[0;34m(q, k, cos, sin, position_ids, unsqueeze_dim)\u001b[0m\n\u001b[1;32m    148\u001b[0m sin \u001b[38;5;241m=\u001b[39m sin\u001b[38;5;241m.\u001b[39munsqueeze(unsqueeze_dim)\n\u001b[1;32m    149\u001b[0m q_embed \u001b[38;5;241m=\u001b[39m (q \u001b[38;5;241m*\u001b[39m cos) \u001b[38;5;241m+\u001b[39m (rotate_half(q) \u001b[38;5;241m*\u001b[39m sin)\n\u001b[0;32m--> 150\u001b[0m k_embed \u001b[38;5;241m=\u001b[39m (k \u001b[38;5;241m*\u001b[39m cos) \u001b[38;5;241m+\u001b[39m (\u001b[43mrotate_half\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m sin)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m q_embed, k_embed\n",
      "File \u001b[0;32m~/santa2024/.venv/lib/python3.12/site-packages/transformers/models/gemma2/modeling_gemma2.py:120\u001b[0m, in \u001b[0;36mrotate_half\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    116\u001b[0m             sin \u001b[38;5;241m=\u001b[39m emb\u001b[38;5;241m.\u001b[39msin()\n\u001b[1;32m    117\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m cos\u001b[38;5;241m.\u001b[39mto(dtype\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mdtype), sin\u001b[38;5;241m.\u001b[39mto(dtype\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrotate_half\u001b[39m(x):\n\u001b[1;32m    121\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Rotates half the hidden dims of the input.\"\"\"\u001b[39;00m\n\u001b[1;32m    122\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, : x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pop = []\n",
    "for _ in range(n_pop):\n",
    "    random.shuffle(words)\n",
    "    words_best = copy.deepcopy(words)\n",
    "    score_best = scorer.get_perplexity(\" \".join(words_best))\n",
    "    pbar = tqdm.tqdm(range(100))\n",
    "    for _ in pbar:\n",
    "        # 16個の近傍を生成\n",
    "        candidates = []\n",
    "        scores = []\n",
    "        for _ in range(16):\n",
    "            words_tmp, _ = make_neighbor(words_best)\n",
    "            candidates.append(words_tmp)\n",
    "            scores.append(scorer.get_perplexity(\" \".join(words_tmp)))\n",
    "        \n",
    "        # 元の解も含めて最良のものを選択\n",
    "        candidates.append(words_best)\n",
    "        scores.append(score_best)\n",
    "        best_idx = min(range(len(scores)), key=lambda i: scores[i])\n",
    "        words_best = candidates[best_idx]\n",
    "        score_best = scores[best_idx]\n",
    "        pbar.set_postfix({\"score\": score_best})\n",
    "    pop.append(words_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_pickle(pop, \"pop_0002_100samples.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jingle grinch holiday eat sing relax unwrap decorations gifts cheer yuletide ornament carol holly stocking magi nutcracker chimney naughty nice sleigh polar beard workshop visit and the of cheer is\n",
      "ornament holiday cheer cheer and eat relax unwrap decorations yuletide chimney stocking magi carol sing grinch the of is nutcracker naughty nice holly jingle sleigh visit workshop polar beard gifts\n",
      "grinch of the eat gifts sing yuletide carol holiday cheer jingle relax unwrap stocking decorations ornament holly naughty and nice nutcracker magi visit chimney beard sleigh workshop polar is cheer\n",
      "sleigh holiday cheer cheer yuletide holly the magi of workshop polar beard unwrap chimney visit nutcracker is naughty nice gifts and grinch eat jingle relax carol sing ornament decorations stocking\n",
      "ornament yuletide stocking gifts of the magi carol grinch holiday cheer holly unwrap cheer and eat relax sing chimney sleigh naughty visit polar workshop jingle beard is nice nutcracker decorations\n",
      "decorations unwrap ornament gifts eat relax cheer holly jingle naughty nice sleigh and the magi visit workshop of grinch is chimney stocking yuletide polar beard nutcracker holiday cheer carol sing\n",
      "sleigh of gifts yuletide jingle grinch is the holiday cheer unwrap ornament stocking magi holly nutcracker polar beard workshop chimney visit naughty nice eat and sing carol relax decorations cheer\n",
      "nutcracker of the magi grinch eat cheer yuletide holly unwrap jingle relax sleigh sing chimney visit polar is beard workshop naughty and nice gifts carol holiday cheer decorations ornament stocking\n",
      "sleigh of cheer cheer jingle relax and eat yuletide grinch holiday is unwrap sing carol the nutcracker decorations ornament holly magi visit polar beard workshop gifts naughty nice chimney stocking\n",
      "sleigh sing unwrap cheer cheer eat and relax jingle grinch naughty of workshop nice the nutcracker polar beard gifts is visit chimney decorations yuletide holiday carol holly ornament stocking magi\n"
     ]
    }
   ],
   "source": [
    "for p in pop:\n",
    "    print(\" \".join(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import get_perplexity_, load_score_memo, save_score_memo\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAEAX:\n",
    "    def __init__(self, words: list[str], words_ppls_map: dict[str, str], scorer, population_size: int = 10, generations: int = 50, initial_pop: list[list[str]] = None):\n",
    "        self.words = words\n",
    "        self.idx_words = {w: i for i, w in enumerate(words)}\n",
    "        self.n_words = len(words)\n",
    "        self.pheromone = np.zeros((self.n_words, self.n_words))\n",
    "        self.words_ppls_map = words_ppls_map\n",
    "        self.population_size = population_size\n",
    "        self.generations = generations\n",
    "        self.calculator = scorer\n",
    "        self.score_memo = {}\n",
    "        self.score_memo_with_error = {}\n",
    "        self.pop = []\n",
    "        if initial_pop is not None:\n",
    "            self.set_population(copy.deepcopy(initial_pop))\n",
    "\n",
    "    def set_population(self, pop: list[list[str]]):\n",
    "        self.pop = pop\n",
    "\n",
    "    def _calc_perplexity(self, words: list[str]) -> float:\n",
    "        idx_bos = words.index(\"<bos>\")\n",
    "        words_use = words[idx_bos+1:] + words[:idx_bos]\n",
    "        words_use = [self.words_ppls_map[w] for w in words_use]\n",
    "        return get_perplexity_(self.calculator, self.score_memo, self.score_memo_with_error, \" \".join(words_use))\n",
    "\n",
    "    def calculate_edge_entropy(self, population: list[list[str]]) -> float:\n",
    "        \"\"\"集団の枝エントロピーを計算\"\"\"\n",
    "        edge_count = {}\n",
    "        total_edges = 0\n",
    "        \n",
    "        for solution in population:\n",
    "            for i in range(len(solution) - 1):\n",
    "                edge = (solution[i], solution[i + 1])\n",
    "                if edge not in edge_count:\n",
    "                    edge_count[edge] = 0\n",
    "                edge_count[edge] += 1\n",
    "                total_edges += 1\n",
    "\n",
    "            edge = (solution[-1], solution[0])\n",
    "            if edge not in edge_count:\n",
    "                edge_count[edge] = 0\n",
    "            edge_count[edge] += 1\n",
    "            total_edges += 1\n",
    "        \n",
    "        entropy = 0.0\n",
    "        for count in edge_count.values():\n",
    "            p = count / total_edges\n",
    "            entropy -= p * math.log(p)\n",
    "        \n",
    "        return entropy\n",
    "\n",
    "    def edge_assembly_crossover(self, parent1_words: list[str], parent2_words: list[str]) -> list[str]:\n",
    "        \"\"\"Edge Assembly Crossoverを実装\"\"\"\n",
    "        n = len(parent1_words)\n",
    "        parent1 = [self.idx_words[w] for w in parent1_words]\n",
    "        parent2 = [self.idx_words[w] for w in parent2_words]\n",
    "        \n",
    "        assert set(parent1) == set(range(n))\n",
    "        assert set(parent2) == set(range(n))\n",
    "\n",
    "        # 両親からエッジ情報を抽出\n",
    "        edges1 = {}\n",
    "        edges1_inv = {}\n",
    "        edges2 = {}\n",
    "        # parent1のエッジ情報を構築\n",
    "        for i in range(len(parent1)):\n",
    "            curr = parent1[i]\n",
    "            next_word = parent1[(i + 1) % n]\n",
    "            edges1[curr] = next_word\n",
    "            edges1_inv[next_word] = curr\n",
    "\n",
    "        # parent2のエッジ情報を構築\n",
    "        for i in range(len(parent2)):\n",
    "            curr = parent2[i]\n",
    "            next_word = parent2[(i + 1) % n]\n",
    "            edges2[curr] = next_word\n",
    "\n",
    "        # ABサイクルの構築\n",
    "        esets = []\n",
    "        used = set()\n",
    "        for i in range(n):\n",
    "            eset_curr = []\n",
    "            curr = i\n",
    "            used.add(curr)\n",
    "            eset_curr.append(curr)\n",
    "\n",
    "            is_a = True\n",
    "            while True:\n",
    "                if is_a:\n",
    "                    nxt = edges1_inv[curr]\n",
    "                else:\n",
    "                    nxt = edges2[curr]\n",
    "                if nxt in used:\n",
    "                    if len(eset_curr) > 2:\n",
    "                        esets.append(eset_curr)\n",
    "                    break\n",
    "                used.add(nxt)\n",
    "                eset_curr.append(nxt)\n",
    "                curr = nxt\n",
    "                is_a = not is_a\n",
    "        if len(esets) == 0: # parent 1 == parent 2\n",
    "            return parent1_words\n",
    "\n",
    "        # choose one eset TOOD: global EAX mode\n",
    "        idx_eset = random.randint(0, len(esets) - 1)\n",
    "        eset = esets[idx_eset]\n",
    "        edge_remove = set()\n",
    "        edge_add = {}\n",
    "        for i in range(len(eset)):\n",
    "            curr = eset[i]\n",
    "            next_word = eset[(i + 1) % len(eset)]\n",
    "            if i % 2 == 0:\n",
    "                edge_remove.add((next_word, curr)) # from parent 1 inv\n",
    "            else:\n",
    "                edge_add[curr] = next_word # from parent 2\n",
    "\n",
    "        edges_offspring = edges1.copy()\n",
    "        for k, v in edge_add.items():\n",
    "            edges_offspring[k] = v\n",
    "            # automatically removed edges from 1 inv\n",
    "\n",
    "        # for i in range(n):\n",
    "        #     edges_offspring[i]\n",
    "        #     edge = (i, edges1[i])\n",
    "        #     if edge not in edge_remove:\n",
    "        #         edges_offspring[i] = edges1[i]\n",
    "        #     else:\n",
    "        #         edges_offspring[i] = edge_add[i]\n",
    "        while True:\n",
    "            # Find disconnected cycles\n",
    "            cycles = []\n",
    "            used = set()\n",
    "            for start in range(n):\n",
    "                if start in used:\n",
    "                    continue\n",
    "                cycle = []\n",
    "                curr = start\n",
    "                while curr not in used:\n",
    "                    cycle.append(curr)\n",
    "                    used.add(curr)\n",
    "                    curr = edges_offspring[curr]\n",
    "                if len(cycle) > 1:\n",
    "                    cycles.append(cycle)\n",
    "\n",
    "            if len(cycles) <= 1:\n",
    "                break\n",
    "\n",
    "            # Select two cycles and connect them\n",
    "            c1, c2 = random.sample(cycles, 2)\n",
    "            \n",
    "            # Find best connection points based on pheromone\n",
    "            max_pheromone = float('-inf')\n",
    "            best_i = best_j = 0\n",
    "            for i in range(len(c1)):\n",
    "                for j in range(len(c2)):\n",
    "                    i_nxt = (i + 1) % len(c1)\n",
    "                    j_nxt = (j + 1) % len(c2)\n",
    "                    pheromone = - self.pheromone[c1[i]][c1[i_nxt]] - self.pheromone[c2[j]][c2[j_nxt]] \\\n",
    "                           + self.pheromone[c1[i]][c2[j_nxt]] + self.pheromone[c2[j]][c1[i_nxt]]\n",
    "                    if pheromone > max_pheromone:\n",
    "                        max_pheromone = pheromone\n",
    "                        best_i = i\n",
    "                        best_j = j\n",
    "\n",
    "            # Reconnect the cycles\n",
    "            edges_offspring[c1[best_i]] = c2[(best_j+1)%len(c2)]\n",
    "            edges_offspring[c2[best_j]] = c1[(best_i+1)%len(c1)]\n",
    "\n",
    "        curr = 0\n",
    "        offspring = [curr]\n",
    "        for _ in range(n - 1):\n",
    "            curr = edges_offspring[curr]\n",
    "            offspring.append(curr)\n",
    "\n",
    "        if set(offspring) != set(range(n)):\n",
    "            # print(\"bug - offspring is broken. use parent1_words\", offspring, parent1_words)\n",
    "            return parent1_words\n",
    "\n",
    "        assert set(offspring) == set(range(n))\n",
    "        return [self.words[i] for i in offspring]\n",
    "\n",
    "    def update_pheromone(self, population: list[list[str]]):\n",
    "        \"\"\"集団のpheromoneを更新\"\"\"\n",
    "        for solution in population:\n",
    "            score = self._calc_perplexity(solution)\n",
    "            for i in range(len(solution)):\n",
    "                word1 = solution[i]\n",
    "                word2 = solution[(i + 1) % len(solution)]\n",
    "                idx1 = self.idx_words[word1]\n",
    "                idx2 = self.idx_words[word2]\n",
    "                self.pheromone[idx1][idx2] += 1.0 / score\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"GA-EAXメインループ\"\"\"\n",
    "        # 初期集団の生成\n",
    "        if not self.pop:\n",
    "            for _ in range(self.population_size):\n",
    "                solution = self.words.copy()\n",
    "                random.shuffle(solution[1:])  # 先頭は固定\n",
    "                self.pop.append(solution)\n",
    "        \n",
    "        scores = [self._calc_perplexity(sol) for sol in self.pop]\n",
    "        best_solution = min(zip(self.pop, scores), key=lambda x: x[1])\n",
    "        self.update_pheromone(self.pop)\n",
    "\n",
    "\n",
    "\n",
    "        pbar = tqdm.tqdm(range(self.generations), desc=\"GA-EAX\")\n",
    "        for gen in pbar:\n",
    "            # 全ての親ペアからoffspringを生成\n",
    "            for i in range(len(self.pop)):\n",
    "                offspring_list = []\n",
    "                offspring_scores = []\n",
    "                for j in range(i+1, len(self.pop)):\n",
    "                    parent1, parent2 = self.pop[i], self.pop[j]\n",
    "                    child = self.edge_assembly_crossover(parent1, parent2)\n",
    "                    child_score = self._calc_perplexity(child)\n",
    "                    offspring_list.append(child)\n",
    "                    offspring_scores.append(child_score)\n",
    "                score_parent = scores[i]\n",
    "                entropy_parent = self.calculate_edge_entropy(self.pop)\n",
    "                best_idx = -1\n",
    "                best_score_diff = 0\n",
    "                eps = 1e-6\n",
    "                for jj, (score, child) in enumerate(zip(offspring_scores, offspring_list)):\n",
    "                    j = i + 1 + jj\n",
    "                    score_diff = score - score_parent\n",
    "                    if score_diff > 0:\n",
    "                        continue\n",
    "                    else:\n",
    "                        pop_new = [p for k, p in enumerate(self.pop) if k != i] + [child]\n",
    "                        entropy = self.calculate_edge_entropy(pop_new)\n",
    "                        entropy_diff = entropy - entropy_parent\n",
    "                        if entropy_diff >= 0.0:\n",
    "                            score_diff = - score_diff / eps\n",
    "                        else:\n",
    "                            score_diff = score_diff / entropy_diff\n",
    "                        if score_diff > best_score_diff:\n",
    "                            best_score_diff = score_diff\n",
    "                            best_idx = jj\n",
    "                if best_idx != -1:\n",
    "                    self.pop[i] = offspring_list[best_idx]\n",
    "                    scores[i] = offspring_scores[best_idx]\n",
    "            \n",
    "            # # 親と子を合わせて評価\n",
    "            # all_solutions = self.pop + offspring_list\n",
    "            # all_scores = scores + offspring_scores\n",
    "            \n",
    "            # スコアの良い順にソート\n",
    "            sorted_solutions = sorted(zip(self.pop, scores), \n",
    "                                   key=lambda x: x[1])\n",
    "            \n",
    "            # # 上位population_size個体を次世代に残す\n",
    "            # self.pop = [sol for sol, _ in sorted_solutions[:self.population_size]]\n",
    "            # scores = [score for _, score in sorted_solutions[:self.population_size]]\n",
    "            \n",
    "            # 最良解の更新\n",
    "            if sorted_solutions[0][1] < best_solution[1]:\n",
    "                best_solution = sorted_solutions[0]\n",
    "                save_text(self.calculator.get_perplexity, 2, \" \".join(best_solution[0]), verbose=1)\n",
    "                print(f\"Best score: {best_solution[1]:.2f}\")\n",
    "                print(f\"Best solution: {best_solution[0]}\")\n",
    "            pbar.set_postfix({\"score\": best_solution[1]})\n",
    "        return best_solution[0], best_solution[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class GAEAX:\n",
    "#     def __init__(self, words: list[str],\n",
    "#                   scorer, population_size: int = 10,\n",
    "#                     generations: int = 50,\n",
    "#                       initial_pop: list[list[str]] = None):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = pd.read_pickle(\"pop_0002_100samples.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = pd.read_pickle(\"pop_0002.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_use = []\n",
    "words_ppls_map = {}\n",
    "for p in pop:\n",
    "    p_use = [\"<bos>\"]\n",
    "    for w in p:\n",
    "        if not w in p_use:\n",
    "            p_use.append(w)\n",
    "            words_ppls_map[w] = w\n",
    "        else:\n",
    "            p_use.append(w + \"1\")\n",
    "            words_ppls_map[w + \"1\"] = w\n",
    "    pop_use.append(p_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_eax = GAEAX(pop_use[0], words_ppls_map, scorer, population_size=10, generations=1000, initial_pop=pop_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = set(pop_use[0])\n",
    "for p in pop_use:\n",
    "    if set(p) != test:\n",
    "        print(len(p), len(set(p)), p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GA-EAX: 100%|██████████| 1000/1000 [00:50<00:00, 19.97it/s, score=318]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['<bos>',\n",
       "  'sleigh',\n",
       "  'of',\n",
       "  'cheer',\n",
       "  'cheer1',\n",
       "  'jingle',\n",
       "  'relax',\n",
       "  'and',\n",
       "  'eat',\n",
       "  'yuletide',\n",
       "  'grinch',\n",
       "  'holiday',\n",
       "  'is',\n",
       "  'unwrap',\n",
       "  'sing',\n",
       "  'carol',\n",
       "  'the',\n",
       "  'nutcracker',\n",
       "  'decorations',\n",
       "  'ornament',\n",
       "  'holly',\n",
       "  'magi',\n",
       "  'visit',\n",
       "  'polar',\n",
       "  'beard',\n",
       "  'workshop',\n",
       "  'gifts',\n",
       "  'naughty',\n",
       "  'nice',\n",
       "  'chimney',\n",
       "  'stocking'],\n",
       " 317.89424036643936)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ga_eax.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_assembly_crossover(parent1: list[str], parent2: list[str]) -> list[str]:\n",
    "    \"\"\"Edge Assembly Crossoverを実装\"\"\"\n",
    "    n = len(parent1)\n",
    "    \n",
    "    # 両親からエッジ情報を抽出\n",
    "    edges = {}\n",
    "    for p in [parent1, parent2]:\n",
    "        for i in range(n-1):\n",
    "            w1, w2 = p[i], p[i+1]\n",
    "            if w1 not in edges:\n",
    "                edges[w1] = set()\n",
    "            edges[w1].add(w2)\n",
    "    \n",
    "    # ABサイクルの構築\n",
    "    result = [\"<bos>\"]  # 開始ワード\n",
    "    used = set([\"<bos>\"])\n",
    "    \n",
    "    while len(result) < n:\n",
    "        curr = result[-1]\n",
    "        # 使用可能なエッジから次のワードを選択\n",
    "        candidates = edges.get(curr, set()) - used\n",
    "        if not candidates:  # 行き詰まった場合\n",
    "            candidates = set(parent1) - used\n",
    "        \n",
    "        next_word = random.choice(list(candidates))\n",
    "        result.append(next_word)\n",
    "        used.add(next_word)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def run_ga_eax(words: list[str], population_size: int = 10, generations: int = 50):\n",
    "    \"\"\"GA-EAXメインループ\"\"\"\n",
    "    # 初期集団の生成\n",
    "    population = []\n",
    "    scores = []\n",
    "    for _ in range(population_size):\n",
    "        solution = words.copy()\n",
    "        random.shuffle(solution[1:])  # <bos>は固定\n",
    "        score = scorer.get_perplexity(\" \".join(solution))\n",
    "        population.append(solution)\n",
    "        scores.append(score)\n",
    "    \n",
    "    best_solution = min(zip(population, scores), key=lambda x: x[1])\n",
    "    \n",
    "    for gen in tqdm.tqdm(range(generations)):\n",
    "        # 親の選択（トーナメント選択）\n",
    "        new_population = []\n",
    "        new_scores = []\n",
    "        \n",
    "        while len(new_population) < population_size:\n",
    "            # 親の選択\n",
    "            parents = random.sample(list(zip(population, scores)), 2)\n",
    "            parent1 = min(parents, key=lambda x: x[1])[0]\n",
    "            parent2 = max(parents, key=lambda x: x[1])[0]\n",
    "            \n",
    "            # 交叉\n",
    "            child = edge_assembly_crossover(parent1, parent2)\n",
    "            \n",
    "            # 局所探索（近傍探索）\n",
    "            for _ in range(5):  # 局所探索の回数\n",
    "                neighbor, _ = make_neighbor(child)\n",
    "                if scorer.get_perplexity(\" \".join(neighbor)) < scorer.get_perplexity(\" \".join(child)):\n",
    "                    child = neighbor\n",
    "            \n",
    "            score = scorer.get_perplexity(\" \".join(child))\n",
    "            new_population.append(child)\n",
    "            new_scores.append(score)\n",
    "            \n",
    "            # 最良解の更新\n",
    "            if score < best_solution[1]:\n",
    "                best_solution = (child, score)\n",
    "                print(f\"Generation {gen}: Best Score = {best_solution[1]:.2f}, solution = {child}\")\n",
    "        \n",
    "        # 世代の更新\n",
    "        population = new_population\n",
    "        scores = new_scores\n",
    "        \n",
    "        if gen % 5 == 0:  # 5世代ごとに経過を表示\n",
    "            print(f\"Generation {gen}: Best Score = {best_solution[1]:.2f}\")\n",
    "    \n",
    "    return best_solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate pheromone matrix from population\n",
    "n_words = len(words)\n",
    "pheromone = np.zeros((n_words, n_words))\n",
    "\n",
    "# Add sentinel nodes for cycle representation\n",
    "words_with_sentinel = [\"<bos>\"] + words + [\"<eos>\"]\n",
    "n_words_with_sentinel = len(words_with_sentinel)\n",
    "\n",
    "# Calculate scores for each solution in population\n",
    "pop_scores = []\n",
    "for solution in pop:\n",
    "    solution_with_sentinel = [\"<bos>\"] + solution + [\"<eos>\"]\n",
    "    score = scorer.get_perplexity(\" \".join(solution))\n",
    "    pop_scores.append(score)\n",
    "\n",
    "# Update pheromone based on solution quality\n",
    "for solution, score in zip(pop, pop_scores):\n",
    "    solution_with_sentinel = [\"<bos>\"] + solution + [\"<eos>\"]\n",
    "    for i in range(n_words_with_sentinel-1):\n",
    "        word1 = solution_with_sentinel[i] \n",
    "        word2 = solution_with_sentinel[i+1]\n",
    "        idx1 = words_with_sentinel.index(word1)\n",
    "        idx2 = words_with_sentinel.index(word2)\n",
    "        # Add pheromone inversely proportional to perplexity\n",
    "        pheromone[idx1][idx2] += 1.0/score\n",
    "\n",
    "# Normalize pheromone matrix\n",
    "pheromone = pheromone / np.sum(pheromone)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"<bos>\"] + words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
